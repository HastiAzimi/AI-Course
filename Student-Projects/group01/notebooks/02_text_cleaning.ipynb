{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "222c2abc-4278-4fd6-a9f7-d73c32460c04",
   "metadata": {},
   "source": [
    "# Text Cleaning & Preprocessing\n",
    "\n",
    "This notebook cleans raw LinkedIn text data\n",
    "to prepare it for sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e56f386-0d78-4fc9-8916-325358add2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation library\n",
    "import pandas as pd\n",
    "\n",
    "# Regular expressions for text cleaning\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d046222-f1c4-4f21-8b71-f85185baeecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 74 rows from ../data/raw/youtube_raw.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to raw data file\n",
    "file_path = \"../data/raw/youtube_raw.csv\"\n",
    "\n",
    "try:\n",
    "    # Load raw CSV data\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Loaded {len(df)} rows from {file_path}\")\n",
    "\n",
    "    # Preview dataset\n",
    "    df.head()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Handle missing file error\n",
    "    print(f\"File not found: {file_path}. Please check the path.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Handle any other unexpected errors\n",
    "    print(f\"Error loading file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c065b44c-4fca-43ee-9c2c-bffc9f972810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NLP tools\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Prepare stopwords and lemmatizer\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean and normalize social media text for NLP tasks\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
    "\n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)\n",
    "\n",
    "    # Keep only letters (English + Persian)\n",
    "    text = re.sub(r\"[^a-zA-Zآ-ی\\s]\", \"\", text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    # Remove stopwords and apply lemmatization\n",
    "    words = [\n",
    "        lemmatizer.lemmatize(w)\n",
    "        for w in text.split()\n",
    "        if w not in stop_words_en\n",
    "    ]\n",
    "\n",
    "    return \" \".join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddb7cb40-8a18-457e-aa90-ecc23e3f2281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied text cleaning on 74 rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if \"content\" in df.columns:\n",
    "    df[\"cleaned_content\"] = df[\"content\"].apply(clean_text)\n",
    "    print(f\"Applied text cleaning on {len(df)} rows.\")\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"Column 'content' not found in DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbec800-ba8f-4a43-bf61-161c80de459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/youtube.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8becefe-cf81-4f3d-8aa0-580dd6211b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Be careful with how many treats the cat gets.....</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>careful many treat cat get right due treat goi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I’m hoping they bring back the plus. Im using ...</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>im hoping bring back plus im using plus upgrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Got my I Phone 17 2 days ago, my battery exper...</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>got phone day ago battery experience bad got t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Watching on my 17.</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>watching</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adding 12 GB of RAM, studio-quality mics, and ...</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>adding gb ram studioquality mics usb would mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>I agree that the iPhone 13 lacks several featu...</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>agree iphone lack several feature understandab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>How the heck are 3 months \"long term\"?</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>heck month long term</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>People with ADHD would notice and love it</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>people adhd would notice love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>interesting comparison, thanks. just a small t...</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>interesting comparison thanks small thing pay ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>I got the XR to broke for another phone</td>\n",
       "      <td>2025-12-24</td>\n",
       "      <td>got xr broke another phone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content        date  \\\n",
       "0   Be careful with how many treats the cat gets.....  2025-12-24   \n",
       "1   I’m hoping they bring back the plus. Im using ...  2025-12-24   \n",
       "2   Got my I Phone 17 2 days ago, my battery exper...  2025-12-24   \n",
       "3                                  Watching on my 17.  2025-12-24   \n",
       "4   Adding 12 GB of RAM, studio-quality mics, and ...  2025-12-24   \n",
       "..                                                ...         ...   \n",
       "69  I agree that the iPhone 13 lacks several featu...  2025-12-24   \n",
       "70             How the heck are 3 months \"long term\"?  2025-12-24   \n",
       "71          People with ADHD would notice and love it  2025-12-24   \n",
       "72  interesting comparison, thanks. just a small t...  2025-12-24   \n",
       "73            I got the XR to broke for another phone  2025-12-24   \n",
       "\n",
       "                                      cleaned_content  \n",
       "0   careful many treat cat get right due treat goi...  \n",
       "1   im hoping bring back plus im using plus upgrad...  \n",
       "2   got phone day ago battery experience bad got t...  \n",
       "3                                            watching  \n",
       "4   adding gb ram studioquality mics usb would mak...  \n",
       "..                                                ...  \n",
       "69  agree iphone lack several feature understandab...  \n",
       "70                               heck month long term  \n",
       "71                      people adhd would notice love  \n",
       "72  interesting comparison thanks small thing pay ...  \n",
       "73                         got xr broke another phone  \n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:twitter_env]",
   "language": "python",
   "name": "conda-env-twitter_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
